{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "bw61 에서 블로킹 I/O와 스레드를 사용하는 TCP 서버를 asyncio와 코루틴을 사용하는 코드로 포팅했음\n",
    "\n",
    "스레드 기반 구현으로부터 asyncio와 코루틴 기반으로 변경하는 방법\n",
    "- 큰 프로그램 전체를 변경하려면 코드 베이스를 점진적으로 마이그레이션하면서 필요에 따라 테스트를 함께 갱신하면서 모든 기능이 제대로 동작하는지 확인해야함\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 스레드 기반 구현으로부터 asyncio와 코루틴 기반으로 변경하는 방법\n",
    "### 구체적 단계\n",
    "1. 최상위 함수가 def대신 async def를 사용하게 변경\n",
    "2. 최상위 함수가 I/O를 호출하는 모든 부분을 asyncio.run_in_executor로 감싸라 (I/O호출하는 부분은 이벤트 루프가 블록될 가능성이 있음)\n",
    "3. run_in_executor 호출이 사용하는 자원이나 콜백이 제대로 동기화 됐는지 확인하라 ( Lock이나 asyncio.run_coroutine_threadsafe 함수를 사용)\n",
    "4. 호출 계층의 앞쪽으로 가면서 중간에 있는 함수와 메서드를 코루틴으로 변환하며 get_event_loop와 run_in_executor 호출을 없애려고 시도하라."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run_thread 함수에 1~3단계를 적용\n",
    "\n",
    "from threading import Lock, Thread\n",
    "\n",
    "def run_threads(handles, interval, output_path):\n",
    "    with open(output_path, 'wb') as output:\n",
    "        lock = Lock()\n",
    "        def write(data):\n",
    "            with lock:\n",
    "                output.write(data)\n",
    "\n",
    "        threads = []\n",
    "        for handle in handles:\n",
    "            args = (handle, interval, write)\n",
    "            thread = Thread(target=tail_file, args=args)\n",
    "            thread.start()\n",
    "            threads.append(thread)\n",
    "\n",
    "        for thread in threads:\n",
    "            thread.join()\n",
    "\n",
    "\n",
    "\n",
    "import asyncio\n",
    "\n",
    "async def run_tasks_mixed(handles, interval, output_path):\n",
    "    loop = asyncio.get_event_loop()\n",
    "\n",
    "    with open(output_path, 'wb') as output:\n",
    "        async def write_async(data):\n",
    "            output.write(data)\n",
    "\n",
    "        def write(data):\n",
    "            coro = write_async(data)\n",
    "            future = asyncio.run_coroutine_threadsafe(\n",
    "                coro, loop)\n",
    "            future.result()\n",
    "\n",
    "        tasks = []\n",
    "        for handle in handles:\n",
    "            task = loop.run_in_executor(\n",
    "                None, tail_file, handle, interval, write)\n",
    "            tasks.append(task)\n",
    "\n",
    "        await asyncio.gather(*tasks)\n",
    "\n",
    "\n",
    "       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- run_in_executor 메서드는 이벤트 루프가 특정 ThreadPoolExecutor나 디폴트 실행기 인스턴스(첫번째 인자 None인 경우)를 사용해 주어진 함수((여기서는 tail_file))를 실행하게 만든다\n",
    "- run_in_executor 함수를 그에 대응하는 await 식 없이 여러번 호출함으로써 run_tasks_mixed 코루틴은 각 입력 파일마다 파일을 한 줄씩 처리하는 작업을 팬아웃 시킨다.\n",
    "- 그후  asyncio.gather 함수와 await 식을 사용해 tail_file이 모두 종료되도록 팬인 시킨다.\n",
    "- 이 코드는 asyncio.run_coroutine_threadsafe 를 사용하기 때문에 Lock 인스턴스와 witer 도우미 함수를 사용할 필요가 없다.\n",
    "- asyncio.run_coroutine_threadsafe 함수를 사용하면 일반적인 작업자 스레드가 코루틴(여기서는 write_async)을 호출해 주 스레드에서 실행되는 이벤트 루프를 통해 실해하도록 만든다\n",
    "- 따라서 스레드 간 동기화가 이뤄지는 효과가 있고 출력 파일에 기록하는 작업이 모두 이벤트 루프에 의해 주 스레드에서 이뤄지도록 보장한다.\n",
    "- asyncio.gather 대기가 끝나면 출력 파일에 대한 데이터 기록도 끝났다고 가정할 수 있으므로 경합 조건이 일어나는 것을 걱정할 필요 없이 with 문을 통해 출력 파일을 close 할 수 있다.\n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "input_paths = ...\n",
    "handles = ...\n",
    "output_path = ...\n",
    "\n",
    "tmpdir, input_paths, handles, output_path = setup()\n",
    "\n",
    "asyncio.run(run_tasks_mixed(handles, 0.1, output_path))\n",
    "\n",
    "confirm_merge(input_paths, output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "\n",
    "async def run_tasks_mixed(handles, interval, output_path):\n",
    "    loop = asyncio.get_event_loop()\n",
    "\n",
    "    with open(output_path, 'wb') as output:\n",
    "        async def write_async(data):\n",
    "            output.write(data)\n",
    "\n",
    "        def write(data):\n",
    "            coro = write_async(data)\n",
    "            future = asyncio.run_coroutine_threadsafe(\n",
    "                coro, loop)\n",
    "            future.result()\n",
    "\n",
    "        tasks = []\n",
    "        for handle in handles:\n",
    "            task = loop.run_in_executor(\n",
    "                None, tail_file, handle, interval, write)\n",
    "            tasks.append(task)\n",
    "\n",
    "        await asyncio.gather(*tasks)\n",
    "\n",
    "\n",
    "# 4단계 적용.   get_event_loop와 run_in_executor 호출을 없애려고 시도\n",
    "\n",
    "async def tail_async(handle, interval, write_func):\n",
    "    loop = asyncio.get_event_loop()\n",
    "\n",
    "    while not handle.closed:\n",
    "        try:\n",
    "            line = await loop.run_in_executor(\n",
    "                None, readline, handle)\n",
    "        except NoNewData:\n",
    "            await asyncio.sleep(interval)\n",
    "        else:\n",
    "            await write_func(line)\n",
    "\n",
    "\n",
    "# 예제 9\n",
    "async def run_tasks(handles, interval, output_path):\n",
    "    with open(output_path, 'wb') as output:\n",
    "        async def write_async(data):\n",
    "            output.write(data)\n",
    "\n",
    "        tasks = []\n",
    "        for handle in handles:\n",
    "            coro = tail_async(handle, interval, write_async)\n",
    "            task = asyncio.create_task(coro)\n",
    "            tasks.append(task)\n",
    "\n",
    "        await asyncio.gather(*tasks)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### run_tasks_mixed 함수에 4단계 적용\n",
    "- 새로운 tail_async 구현을 사용하면 get_event_loop와 run_in_executor를 run_tasks_mixed 함수에서 완전히 제거해 호출 계측 한 단계 아래로 내려보낼 수 있다\n",
    "- 그러면 깔끄하고 훨씬 쫓아가기 쉬운 코드만 남는다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 이런식으로 반복적인 리팩터링 패턴을 계속 진행하면서 readline 함수를 비동기 코루틴으로 변경할 수 있다.\n",
    "- 하지만 이 함수는 너무 많은 블록킹 파일 I/O연산을 사용하므로 성능 저하와 코드 명황성 저하를 가져온다는 점에서 asyncio 로 포팅하기에 적합하지 않아 보인다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 상향식 접근법도 하향식과 똑같은 형태로 끝남\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 결론\n",
    "- asyncio 이벤트 루프의 run_in_executor를 메서드(await를 사용해 완료를 기다릴 수 있음)를 사용하면 코루틴이 ThreadPoolExecutor 스레드 풀을 사용해 동기적인 함수를 호출 할 수 있다. 이 기능을 사용하면 하향식으로  asyncio 마이그레이션 할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 코드 전문\n",
    "\n",
    "import random\n",
    "random.seed(1234)\n",
    "\n",
    "import logging\n",
    "from pprint import pprint\n",
    "from sys import stdout as STDOUT\n",
    "\n",
    "# 모든 출력을 임시 디렉터리에 기록함\n",
    "import atexit\n",
    "import gc\n",
    "import io\n",
    "import os\n",
    "import tempfile\n",
    "\n",
    "TEST_DIR = tempfile.TemporaryDirectory()\n",
    "atexit.register(TEST_DIR.cleanup)\n",
    "\n",
    "# 윈도우에서 프로세스 깔끔하게 종료하기\n",
    "OLD_CWD = os.getcwd()\n",
    "atexit.register(lambda: os.chdir(OLD_CWD))\n",
    "os.chdir(TEST_DIR.name)\n",
    "\n",
    "def close_open_files():\n",
    "    everything = gc.get_objects()\n",
    "    for obj in everything:\n",
    "        if isinstance(obj, io.IOBase):\n",
    "            obj.close()\n",
    "\n",
    "atexit.register(close_open_files)\n",
    "\n",
    "\n",
    "# 예제 1\n",
    "class NoNewData(Exception):\n",
    "    pass\n",
    "\n",
    "def readline(handle):\n",
    "    offset = handle.tell()\n",
    "    handle.seek(0, 2)\n",
    "    length = handle.tell()\n",
    "\n",
    "    if length == offset:\n",
    "        raise NoNewData\n",
    "\n",
    "    handle.seek(offset, 0)\n",
    "    return handle.readline()\n",
    "\n",
    "\n",
    "# 예제 2\n",
    "import time\n",
    "\n",
    "def tail_file(handle, interval, write_func):\n",
    "    while not handle.closed:\n",
    "        try:\n",
    "            line = readline(handle)\n",
    "        except NoNewData:\n",
    "            time.sleep(interval)\n",
    "        else:\n",
    "            write_func(line)\n",
    "\n",
    "\n",
    "# 예제 3\n",
    "from threading import Lock, Thread\n",
    "\n",
    "def run_threads(handles, interval, output_path):\n",
    "    with open(output_path, 'wb') as output:\n",
    "        lock = Lock()\n",
    "        def write(data):\n",
    "            with lock:\n",
    "                output.write(data)\n",
    "\n",
    "        threads = []\n",
    "        for handle in handles:\n",
    "            args = (handle, interval, write)\n",
    "            thread = Thread(target=tail_file, args=args)\n",
    "            thread.start()\n",
    "            threads.append(thread)\n",
    "\n",
    "        for thread in threads:\n",
    "            thread.join()\n",
    "\n",
    "\n",
    "# 예제 4\n",
    "# 핸들에 쓰는 프로세스를 에뮬레이션하는 코드\n",
    "import collections\n",
    "import os\n",
    "import random\n",
    "import string\n",
    "from tempfile import TemporaryDirectory\n",
    "\n",
    "def write_random_data(path, write_count, interval):\n",
    "    with open(path, 'wb') as f:\n",
    "        for i in range(write_count):\n",
    "            time.sleep(random.random() * interval)\n",
    "            letters = random.choices(\n",
    "                string.ascii_lowercase, k=10)\n",
    "            data = f'{path}-{i:02}-{\"\".join(letters)}\\n'\n",
    "            f.write(data.encode())\n",
    "            f.flush()\n",
    "\n",
    "def start_write_threads(directory, file_count):\n",
    "    paths = []\n",
    "    for i in range(file_count):\n",
    "        path = os.path.join(directory, str(i))\n",
    "        with open(path, 'w'):\n",
    "            # 읽기 스레드가 파일을 폴링하기 전에 경로상 파일이 존재하는지 확실히 하자\n",
    "            pass\n",
    "        paths.append(path)\n",
    "        args = (path, 10, 0.1)\n",
    "        thread = Thread(target=write_random_data, args=args)\n",
    "        thread.start()\n",
    "    return paths\n",
    "\n",
    "def close_all(handles):\n",
    "    time.sleep(1)\n",
    "    for handle in handles:\n",
    "        handle.close()\n",
    "\n",
    "def setup():\n",
    "    tmpdir = TemporaryDirectory()\n",
    "    input_paths = start_write_threads(tmpdir.name, 5)\n",
    "\n",
    "    handles = []\n",
    "    for path in input_paths:\n",
    "        handle = open(path, 'rb')\n",
    "        handles.append(handle)\n",
    "\n",
    "    Thread(target=close_all, args=(handles,)).start()\n",
    "\n",
    "    output_path = os.path.join(tmpdir.name, 'merged')\n",
    "    return tmpdir, input_paths, handles, output_path\n",
    "\n",
    "\n",
    "# 예제 5\n",
    "def confirm_merge(input_paths, output_path):\n",
    "    found = collections.defaultdict(list)\n",
    "    with open(output_path, 'rb') as f:\n",
    "        for line in f:\n",
    "            for path in input_paths:\n",
    "                if line.find(path.encode()) == 0:\n",
    "                    found[path].append(line)\n",
    "\n",
    "    expected = collections.defaultdict(list)\n",
    "    for path in input_paths:\n",
    "        with open(path, 'rb') as f:\n",
    "            expected[path].extend(f.readlines())\n",
    "\n",
    "    for key, expected_lines in expected.items():\n",
    "        found_lines = found[key]\n",
    "        assert expected_lines == found_lines, \\\n",
    "            f'{expected_lines!r} == {found_lines!r}'\n",
    "\n",
    "input_paths = ...\n",
    "handles = ...\n",
    "output_path = ...\n",
    "\n",
    "tmpdir, input_paths, handles, output_path = setup()\n",
    "\n",
    "run_threads(handles, 0.1, output_path)\n",
    "\n",
    "confirm_merge(input_paths, output_path)\n",
    "\n",
    "tmpdir.cleanup()\n",
    "\n",
    "\n",
    "# 예제 6\n",
    "import asyncio\n",
    "\n",
    "# 윈도우에서는 ProactorEventLoop가 시그널 핸들러를 등록하려고 시도하기 때문에\n",
    "# 스레드 안에서 ProactorEventLoop를 만들 수 없다.\n",
    "#\n",
    "# 대신 SelectEventLoop 정책을 사용하는 방식으로 우회한다.\n",
    "# 참고: https://bugs.python.org/issue33792\n",
    "policy = asyncio.get_event_loop_policy()\n",
    "policy._loop_factory = asyncio.SelectorEventLoop\n",
    "\n",
    "async def run_tasks_mixed(handles, interval, output_path):\n",
    "    loop = asyncio.get_event_loop()\n",
    "\n",
    "    with open(output_path, 'wb') as output:\n",
    "        async def write_async(data):\n",
    "            output.write(data)\n",
    "\n",
    "        def write(data):\n",
    "            coro = write_async(data)\n",
    "            future = asyncio.run_coroutine_threadsafe(\n",
    "                coro, loop)\n",
    "            future.result()\n",
    "\n",
    "        tasks = []\n",
    "        for handle in handles:\n",
    "            task = loop.run_in_executor(\n",
    "                None, tail_file, handle, interval, write)\n",
    "            tasks.append(task)\n",
    "\n",
    "        await asyncio.gather(*tasks)\n",
    "\n",
    "\n",
    "# 예제 7\n",
    "input_paths = ...\n",
    "handles = ...\n",
    "output_path = ...\n",
    "\n",
    "tmpdir, input_paths, handles, output_path = setup()\n",
    "\n",
    "asyncio.run(run_tasks_mixed(handles, 0.1, output_path))\n",
    "\n",
    "confirm_merge(input_paths, output_path)\n",
    "\n",
    "tmpdir.cleanup()\n",
    "\n",
    "\n",
    "# 예제 8\n",
    "async def tail_async(handle, interval, write_func):\n",
    "    loop = asyncio.get_event_loop()\n",
    "\n",
    "    while not handle.closed:\n",
    "        try:\n",
    "            line = await loop.run_in_executor(\n",
    "                None, readline, handle)\n",
    "        except NoNewData:\n",
    "            await asyncio.sleep(interval)\n",
    "        else:\n",
    "            await write_func(line)\n",
    "\n",
    "\n",
    "# 예제 9\n",
    "async def run_tasks(handles, interval, output_path):\n",
    "    with open(output_path, 'wb') as output:\n",
    "        async def write_async(data):\n",
    "            output.write(data)\n",
    "\n",
    "        tasks = []\n",
    "        for handle in handles:\n",
    "            coro = tail_async(handle, interval, write_async)\n",
    "            task = asyncio.create_task(coro)\n",
    "            tasks.append(task)\n",
    "\n",
    "        await asyncio.gather(*tasks)\n",
    "\n",
    "\n",
    "# 예제 10\n",
    "input_paths = ...\n",
    "handles = ...\n",
    "output_path = ...\n",
    "\n",
    "tmpdir, input_paths, handles, output_path = setup()\n",
    "\n",
    "asyncio.run(run_tasks(handles, 0.1, output_path))\n",
    "\n",
    "confirm_merge(input_paths, output_path)\n",
    "\n",
    "tmpdir.cleanup()\n",
    "\n",
    "\n",
    "# 예제 11\n",
    "def tail_file(handle, interval, write_func):\n",
    "    loop = asyncio.new_event_loop()\n",
    "    asyncio.set_event_loop(loop)\n",
    "\n",
    "    async def write_async(data):\n",
    "        write_func(data)\n",
    "\n",
    "    # 맨 마지막에 한번 더 이벤트 루프를 실행해서\n",
    "    # 다른 이벤트 루프가 stop()에 await하는 경우를 해결한다.\n",
    "    coro = tail_async(handle, interval, write_async)\n",
    "    loop.run_until_complete(coro)\n",
    "\n",
    "\n",
    "# 예제 12\n",
    "input_paths = ...\n",
    "handles = ...\n",
    "output_path = ...\n",
    "\n",
    "tmpdir, input_paths, handles, output_path = setup()\n",
    "\n",
    "run_threads(handles, 0.1, output_path)\n",
    "\n",
    "confirm_merge(input_paths, output_path)\n",
    "\n",
    "tmpdir.cleanup()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "9f1543dab12f68711edff4aaa40dc64b55bdb8a196ed66d96303cc511487faa6"
  },
  "kernelspec": {
   "display_name": "Python 3.8.11 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
